{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a13b007f",
   "metadata": {},
   "source": [
    "This is the initial notebook to explore the data and run the first models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "789f7c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from fastai.imports import *\n",
    "from fastai.tabular.all import *\n",
    "\n",
    "from numpy import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "from scipy.stats import skew, norm\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "from scipy.special import boxcox1p\n",
    "from scipy.stats import boxcox_normmax\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "3af42dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "sample = pd.read_csv('sample_submission.csv')\n",
    "train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c5e835",
   "metadata": {},
   "source": [
    "Based on initial analysis the train and test datasets have similar characteristics, so it will be easier to combine them for imputation and data analysis work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "e1e76d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test = pd.concat([train, test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "331f1180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSZoning           4\n",
       "LotFrontage      486\n",
       "Alley           2721\n",
       "Utilities          2\n",
       "Exterior1st        1\n",
       "Exterior2nd        1\n",
       "MasVnrType        24\n",
       "MasVnrArea        23\n",
       "BsmtQual          81\n",
       "BsmtCond          82\n",
       "BsmtExposure      82\n",
       "BsmtFinType1      79\n",
       "BsmtFinSF1         1\n",
       "BsmtFinType2      80\n",
       "BsmtFinSF2         1\n",
       "BsmtUnfSF          1\n",
       "TotalBsmtSF        1\n",
       "Electrical         1\n",
       "BsmtFullBath       2\n",
       "BsmtHalfBath       2\n",
       "KitchenQual        1\n",
       "Functional         2\n",
       "FireplaceQu     1420\n",
       "GarageType       157\n",
       "GarageYrBlt      159\n",
       "GarageFinish     159\n",
       "GarageCars         1\n",
       "GarageArea         1\n",
       "GarageQual       159\n",
       "GarageCond       159\n",
       "PoolQC          2909\n",
       "Fence           2348\n",
       "MiscFeature     2814\n",
       "SaleType           1\n",
       "SalePrice       1459\n",
       "dtype: int64"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(train_test).sum()[pd.isnull(train_test).sum() > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d0316a",
   "metadata": {},
   "source": [
    "It looks like Alley, FireplaceQu, PoolQC, Fence and MiscFeature have significant numbers of missing data. So it will be best to eliminate those rows. There are a number of rows that have less than 5 rows with missing data. Since some of these are categorical and some are continuous data, their missing data will be replaced with the most frequent value. \n",
    "\n",
    "Instead, for high_nan, replace the NaN with None; since they don't have that feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "29ab3f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_high_nan=['Alley','FireplaceQu','PoolQC','Fence','MiscFeature']\n",
    "train_test=train_test.drop(drop_high_nan,axis=1)\n",
    "\n",
    "small_nan_cols = ['MSZoning', 'Utilities', 'Exterior1st', 'Exterior2nd', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', \n",
    "                  'TotalBsmtSF', 'Electrical', 'BsmtFullBath', 'BsmtHalfBath', 'KitchenQual', 'Functional', 'GarageCars', \n",
    "                  'GarageArea','SaleType', 'SaleCondition']\n",
    "small_impute = SimpleImputer(strategy='most_frequent')\n",
    "train_test[small_nan_cols] = pd.DataFrame(small_impute.fit_transform(train_test[small_nan_cols]),columns=small_nan_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1be893",
   "metadata": {},
   "source": [
    "The following columns seem to have one value significantly larger than the rest, and it would probably be best to use the mode, or most common, value to feel each NaN value: MasVnrType, MasVnrArea, BsmtCond, BsmtExposure, BsmtFinType2, GarageType, GarageFinish, GarageQual, and GarageCond. That is represents 9 out of the 13 columns. \n",
    "\n",
    "BsmtQual has two values larger than the rest: Gd and TA. But it only has 2.8% NaNs, so simply using the mode might be good enough.  \n",
    "\n",
    "GarageYrBlt has 59 NaNs out 2919 rows which is only 2%. It has a dispersed set of values, so it might be easiest just to have any NaNs have the same value as YearBuilt. \n",
    "\n",
    "BsmtFinType1 has only 2.7% value of NaNs, and most two of its largest values are GLQ and Unf. It might be easiest to use the mode here. \n",
    "\n",
    "LotFrontage has 486 NaNs out of 2919 rows which is a pretty high 16.7%. It has a dispersed range of values, but looking at its characteristics from the describe function above, it seems to have a pretty even distribution with a mean of 10,168 and a median of 9,453. So using the mean to fill in the NaNs seems reasonable. If it turns out this value has a high impact on the predictability of the SalePrice, then it might be good to revisit this assumption. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "c4271ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_cols = ['MasVnrType', 'MasVnrArea', 'BsmtCond', 'BsmtExposure', 'BsmtFinType2', 'GarageType', 'GarageFinish', \n",
    "             'GarageQual','GarageCond', 'BsmtQual', 'BsmtFinType1']\n",
    "mode_impute = SimpleImputer(strategy='most_frequent')\n",
    "train_test[mode_cols] = pd.DataFrame(mode_impute.fit_transform(train_test[mode_cols]),columns=mode_cols)\n",
    "train_test['LotFrontage'].fillna((train_test['LotFrontage'].mean()), inplace=True)\n",
    "train_test['GarageYrBlt'] = train_test['GarageYrBlt'].fillna(train_test['YearBuilt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "80091d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SalePrice    1459\n",
       "dtype: int64"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(train_test).sum()[pd.isnull(train_test).sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "46b9042f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Gd', 'TA', 'Ex', 'Fa'], dtype=object)"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test['BsmtQual'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "68371091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['GLQ', 'ALQ', 'Unf', 'Rec', 'BLQ', 'LwQ'], dtype=object)"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test['BsmtFinType1'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "12457a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test.BsmtQual = train_test.BsmtQual.replace({\"Ex\": 110, \"Gd\": 95, \"TA\": 85, \"Fa\": 75, \"Po\": 60, \"NA\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "1425c71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test.BsmtFinType1 = train_test.BsmtFinType1.replace({\"GLQ\": 6, \"ALQ\": 5, \"BLQ\": 4, \"Rec\": 3, \"LwQ\": 2, \"Unf\": 1,\n",
    "                                                         \"NA\": 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a231025",
   "metadata": {},
   "source": [
    "To look at how many features have a skew above 0.5, since high skew can be an issue in regression analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "44ff7ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Id',\n",
       " 'MSSubClass',\n",
       " 'LotFrontage',\n",
       " 'LotArea',\n",
       " 'OverallQual',\n",
       " 'OverallCond',\n",
       " 'YearBuilt',\n",
       " 'YearRemodAdd',\n",
       " 'BsmtQual',\n",
       " 'BsmtFinType1',\n",
       " '1stFlrSF',\n",
       " '2ndFlrSF',\n",
       " 'LowQualFinSF',\n",
       " 'GrLivArea',\n",
       " 'FullBath',\n",
       " 'HalfBath',\n",
       " 'BedroomAbvGr',\n",
       " 'KitchenAbvGr',\n",
       " 'TotRmsAbvGrd',\n",
       " 'Fireplaces',\n",
       " 'GarageYrBlt',\n",
       " 'WoodDeckSF',\n",
       " 'OpenPorchSF',\n",
       " 'EnclosedPorch',\n",
       " '3SsnPorch',\n",
       " 'ScreenPorch',\n",
       " 'PoolArea',\n",
       " 'MiscVal',\n",
       " 'MoSold',\n",
       " 'YrSold',\n",
       " 'SalePrice']"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_cols = train_test.select_dtypes(include=np.number).columns.tolist()\n",
    "number_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "96c88d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MiscVal', 'PoolArea', 'LotArea', 'LowQualFinSF', '3SsnPorch',\n",
       "       'KitchenAbvGr', 'EnclosedPorch', 'ScreenPorch', 'OpenPorchSF',\n",
       "       'WoodDeckSF', 'LotFrontage', '1stFlrSF', 'MSSubClass', 'GrLivArea',\n",
       "       '2ndFlrSF', 'BsmtQual', 'TotRmsAbvGrd', 'Fireplaces', 'HalfBath'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skew_features = train_test[number_cols].apply(lambda x: skew(x)).sort_values(ascending=False)\n",
    "high_skew = skew_features[skew_features > 0.6]\n",
    "skew_index = high_skew.index\n",
    "skew_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "d624c669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 19 numerical features with Skew > 0.6 :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MiscVal</th>\n",
       "      <td>21.947195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PoolArea</th>\n",
       "      <td>16.898328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotArea</th>\n",
       "      <td>12.822431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <td>12.088761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3SsnPorch</th>\n",
       "      <td>11.376065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <td>4.302254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <td>4.003891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ScreenPorch</th>\n",
       "      <td>3.946694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <td>2.535114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <td>1.842433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotFrontage</th>\n",
       "      <td>1.645574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1stFlrSF</th>\n",
       "      <td>1.469604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSSubClass</th>\n",
       "      <td>1.375457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GrLivArea</th>\n",
       "      <td>1.269358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <td>0.861675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtQual</th>\n",
       "      <td>0.796302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <td>0.758367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fireplaces</th>\n",
       "      <td>0.733495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HalfBath</th>\n",
       "      <td>0.694566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Skew\n",
       "MiscVal        21.947195\n",
       "PoolArea       16.898328\n",
       "LotArea        12.822431\n",
       "LowQualFinSF   12.088761\n",
       "3SsnPorch      11.376065\n",
       "KitchenAbvGr    4.302254\n",
       "EnclosedPorch   4.003891\n",
       "ScreenPorch     3.946694\n",
       "OpenPorchSF     2.535114\n",
       "WoodDeckSF      1.842433\n",
       "LotFrontage     1.645574\n",
       "1stFlrSF        1.469604\n",
       "MSSubClass      1.375457\n",
       "GrLivArea       1.269358\n",
       "2ndFlrSF        0.861675\n",
       "BsmtQual        0.796302\n",
       "TotRmsAbvGrd    0.758367\n",
       "Fireplaces      0.733495\n",
       "HalfBath        0.694566"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"There are {} numerical features with Skew > 0.6 :\".format(high_skew.shape[0]))\n",
    "skewness = pd.DataFrame({'Skew' :high_skew})\n",
    "skewness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9ecf2b",
   "metadata": {},
   "source": [
    "To normalize the features with skew above 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "99f32924",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in skew_index:\n",
    "    train_test[i] = np.log1p(train_test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cd0509",
   "metadata": {},
   "source": [
    "It will be necessary to identify all the columns that have non-numeric object values and then convert them to numeric values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "80aaa6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_cols = list(train_test.select_dtypes(['object']).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "62baae01",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in obj_cols:\n",
    "     train_test[column] = pd.factorize(train_test[column], sort=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086c88f7",
   "metadata": {},
   "source": [
    "To create some new columns that might compound the effects of the existing columns with higher impact on the xgb score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "36eb99a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test['QualCondSum'] = train_test['OverallQual'] + train_test['OverallCond']\n",
    "train_test['RemodTime'] = train_test['YearRemodAdd'] - train_test['YearBuilt']\n",
    "train_test['BsmtFinTypeSF1'] = train_test['BsmtFinType1'] * train_test['BsmtFinSF1']\n",
    "train_test['TotalFlrSF'] = train_test['1stFlrSF'] + train_test['2ndFlrSF']\n",
    "train_test['TotalFinSF'] = train_test['GrLivArea'] + train_test['BsmtFinSF1']\n",
    "train_test['GarageCarArea'] = train_test['GarageArea'] * train_test['GarageCars']\n",
    "train_test['TotalSF'] = train_test['1stFlrSF'] + train_test['2ndFlrSF'] + train_test['TotalBsmtSF']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c5aaf2",
   "metadata": {},
   "source": [
    "To now eliminate the columns that have negative or zero influence on the xgb score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "8a8669c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test.drop(['Utilities','Street','TotRmsAbvGrd','3SsnPorch','YrSold','Exterior2nd','LotConfig',\n",
    "                              'HouseStyle','EnclosedPorch','WoodDeckSF','Foundation','RoofMatl','Electrical',\n",
    "                              'GarageType','LotFrontage','SaleType','MoSold','BsmtExposure','1stFlrSF',\n",
    "                              'BsmtFinSF1','Exterior1st','KitchenQual','TotalFlrSF'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48390e60",
   "metadata": {},
   "source": [
    "To create a column with the log of the SalePrice to match the evaluation process in the contest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "77ad85f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test['LogSalePrice'] = train_test['SalePrice'].apply(np.log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d04cdb9",
   "metadata": {},
   "source": [
    "WHY THESE FEATURES? HOW DOES IT WORK?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "a3487e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers\n",
    "train_test.drop(train_test[(train_test['OverallQual']<5) & (train_test['LogSalePrice']>200000)].index, inplace=True)\n",
    "train_test.drop(train_test[(train['GrLivArea']>4500) & (train_test['LogSalePrice']<300000)].index, inplace=True)\n",
    "train_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1baca8c9",
   "metadata": {},
   "source": [
    "To separate the train_test dataset back into the train and test datasets, identify the independent and dependent columns, and create the validation split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "c5bba200",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_test[train_test['SalePrice'].notnull()].copy()\n",
    "test = train_test[train_test['SalePrice'].isnull()].drop(['SalePrice','LogSalePrice'],axis=1)\n",
    "X = train.drop(['SalePrice','LogSalePrice'],axis=1)\n",
    "y = train.LogSalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "039b618c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = shuffle(X,y, random_state=42)\n",
    "X = X.reset_index(drop=True)\n",
    "y = y.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2d7aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49f7ff4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "44fd6059",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_cv(model,X,y):\n",
    "    rmse = np.sqrt(-cross_val_score(model, X, y, scoring=\"neg_mean_squared_error\", cv=12))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0547b84b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "9ad2452d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "6ab7752d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12544640063829113\n"
     ]
    }
   ],
   "source": [
    "print(rmse_cv(xgb_model,X,y).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b384a10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "971bed74",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = test[['Id']]\n",
    "submit = submit.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "307d593d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "c0e70573",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_predict = xgb_model.predict(test)\n",
    "submit_predict = np.exp(submit_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "0342d3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['SalePrice'] = submit_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "395cc685",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('submit_xgb-03-try.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6608dff0",
   "metadata": {},
   "source": [
    "Baseline. model=0.1379, Kaggle=0.14155\n",
    "\n",
    "CV = 12. model=0.1305, Kaggle=0.14155\n",
    "\n",
    "Remove outliers. model=0.12626\n",
    "\n",
    "Fill drop_high_nan columns with 'None' instead of dropping them. model=0.1271; DON'T USE THIS\n",
    "\n",
    "Fix skew to be before numerizing objects. model=0.12545    Kaggle=0.14874\n",
    "\n",
    "Not removing negative influencing features. model=0.13138; DON'T USE THIS\n",
    "\n",
    "Tried to use pd.get_dummies on astype 'object' data, but created over 19,000 columns\n",
    "\n",
    "Using his parameters for XGBRegressor. model=0.13558 DON'T USE THIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2330e12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
