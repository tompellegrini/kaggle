{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a13b007f",
   "metadata": {},
   "source": [
    "This is the initial notebook to explore the data and run the first models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "789f7c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from fastai.imports import *\n",
    "from fastai.tabular.all import *\n",
    "\n",
    "from numpy import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "from scipy.stats import skew, norm\n",
    "from scipy.special import boxcox1p\n",
    "from scipy.stats import boxcox_normmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3af42dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "sample = pd.read_csv('sample_submission.csv')\n",
    "train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c5e835",
   "metadata": {},
   "source": [
    "Based on initial analysis the train and test datasets have similar characteristics, so it will be easier to combine them for imputation and data analysis work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1e76d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test = pd.concat([train, test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "331f1180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSZoning           4\n",
       "LotFrontage      486\n",
       "Alley           2721\n",
       "Utilities          2\n",
       "Exterior1st        1\n",
       "Exterior2nd        1\n",
       "MasVnrType        24\n",
       "MasVnrArea        23\n",
       "BsmtQual          81\n",
       "BsmtCond          82\n",
       "BsmtExposure      82\n",
       "BsmtFinType1      79\n",
       "BsmtFinSF1         1\n",
       "BsmtFinType2      80\n",
       "BsmtFinSF2         1\n",
       "BsmtUnfSF          1\n",
       "TotalBsmtSF        1\n",
       "Electrical         1\n",
       "BsmtFullBath       2\n",
       "BsmtHalfBath       2\n",
       "KitchenQual        1\n",
       "Functional         2\n",
       "FireplaceQu     1420\n",
       "GarageType       157\n",
       "GarageYrBlt      159\n",
       "GarageFinish     159\n",
       "GarageCars         1\n",
       "GarageArea         1\n",
       "GarageQual       159\n",
       "GarageCond       159\n",
       "PoolQC          2909\n",
       "Fence           2348\n",
       "MiscFeature     2814\n",
       "SaleType           1\n",
       "SalePrice       1459\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(train_test).sum()[pd.isnull(train_test).sum() > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d0316a",
   "metadata": {},
   "source": [
    "It looks like Alley, FireplaceQu, PoolQC, Fence and MiscFeature have significant numbers of missing data. So it will be best to eliminate those rows. There are a number of rows that have less than 5 rows with missing data. Since some of these are categorical and some are continuous data, their missing data will be replaced with the most frequent value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29ab3f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_high_nan=['Alley','FireplaceQu','PoolQC','Fence','MiscFeature']\n",
    "train_test=train_test.drop(drop_high_nan,axis=1)\n",
    "small_nan_cols = ['MSZoning', 'Utilities', 'Exterior1st', 'Exterior2nd', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', \n",
    "                  'TotalBsmtSF', 'Electrical', 'BsmtFullBath', 'BsmtHalfBath', 'KitchenQual', 'Functional', 'GarageCars', \n",
    "                  'GarageArea','SaleType', 'SaleCondition']\n",
    "small_impute = SimpleImputer(strategy='most_frequent')\n",
    "train_test[small_nan_cols] = pd.DataFrame(small_impute.fit_transform(train_test[small_nan_cols]),columns=small_nan_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1be893",
   "metadata": {},
   "source": [
    "The following columns seem to have one value significantly larger than the rest, and it would probably be best to use the mode, or most common, value to feel each NaN value: MasVnrType, MasVnrArea, BsmtCond, BsmtExposure, BsmtFinType2, GarageType, GarageFinish, GarageQual, and GarageCond. That is represents 9 out of the 13 columns. \n",
    "\n",
    "BsmtQual has two values larger than the rest: Gd and TA. But it only has 2.8% NaNs, so simply using the mode might be good enough.  \n",
    "\n",
    "GarageYrBlt has 59 NaNs out 2919 rows which is only 2%. It has a dispersed set of values, so it might be easiest just to have any NaNs have the same value as YearBuilt. \n",
    "\n",
    "BsmtFinType1 has only 2.7% value of NaNs, and most two of its largest values are GLQ and Unf. It might be easiest to use the mode here. \n",
    "\n",
    "LotFrontage has 486 NaNs out of 2919 rows which is a pretty high 16.7%. It has a dispersed range of values, but looking at its characteristics from the describe function above, it seems to have a pretty even distribution with a mean of 10,168 and a median of 9,453. So using the mean to fill in the NaNs seems reasonable. If it turns out this value has a high impact on the predictability of the SalePrice, then it might be good to revisit this assumption. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4271ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_cols = ['MasVnrType', 'MasVnrArea', 'BsmtCond', 'BsmtExposure', 'BsmtFinType2', 'GarageType', 'GarageFinish', \n",
    "             'GarageQual','GarageCond', 'BsmtQual', 'BsmtFinType1']\n",
    "mode_impute = SimpleImputer(strategy='most_frequent')\n",
    "train_test[mode_cols] = pd.DataFrame(mode_impute.fit_transform(train_test[mode_cols]),columns=mode_cols)\n",
    "train_test['LotFrontage'].fillna((train_test['LotFrontage'].mean()), inplace=True)\n",
    "train_test['GarageYrBlt'] = train_test['GarageYrBlt'].fillna(train_test['YearBuilt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80091d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SalePrice    1459\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(train_test).sum()[pd.isnull(train_test).sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46b9042f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Gd', 'TA', 'Ex', 'Fa'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test['BsmtQual'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68371091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['GLQ', 'ALQ', 'Unf', 'Rec', 'BLQ', 'LwQ'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test['BsmtFinType1'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12457a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test.BsmtQual = train_test.BsmtQual.replace({\"Ex\": 110, \"Gd\": 95, \"TA\": 85, \"Fa\": 75, \"Po\": 60, \"NA\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1425c71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test.BsmtFinType1 = train_test.BsmtFinType1.replace({\"GLQ\": 6, \"ALQ\": 5, \"BLQ\": 4, \"Rec\": 3, \"LwQ\": 2, \"Unf\": 1,\n",
    "                                                         \"NA\": 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cd0509",
   "metadata": {},
   "source": [
    "It will be necessary to identify all the columns that have non-numeric object values and then convert them to numeric values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80aaa6ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MSZoning',\n",
       " 'Street',\n",
       " 'LotShape',\n",
       " 'LandContour',\n",
       " 'Utilities',\n",
       " 'LotConfig',\n",
       " 'LandSlope',\n",
       " 'Neighborhood',\n",
       " 'Condition1',\n",
       " 'Condition2',\n",
       " 'BldgType',\n",
       " 'HouseStyle',\n",
       " 'RoofStyle',\n",
       " 'RoofMatl',\n",
       " 'Exterior1st',\n",
       " 'Exterior2nd',\n",
       " 'MasVnrType',\n",
       " 'MasVnrArea',\n",
       " 'ExterQual',\n",
       " 'ExterCond',\n",
       " 'Foundation',\n",
       " 'BsmtCond',\n",
       " 'BsmtExposure',\n",
       " 'BsmtFinSF1',\n",
       " 'BsmtFinType2',\n",
       " 'BsmtFinSF2',\n",
       " 'BsmtUnfSF',\n",
       " 'TotalBsmtSF',\n",
       " 'Heating',\n",
       " 'HeatingQC',\n",
       " 'CentralAir',\n",
       " 'Electrical',\n",
       " 'BsmtFullBath',\n",
       " 'BsmtHalfBath',\n",
       " 'KitchenQual',\n",
       " 'Functional',\n",
       " 'GarageType',\n",
       " 'GarageFinish',\n",
       " 'GarageCars',\n",
       " 'GarageArea',\n",
       " 'GarageQual',\n",
       " 'GarageCond',\n",
       " 'PavedDrive',\n",
       " 'SaleType',\n",
       " 'SaleCondition']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_cols = list(train_test.select_dtypes(['object']).columns)\n",
    "obj_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62baae01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tompe\\anaconda3\\lib\\site-packages\\pandas\\core\\algorithms.py:798: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  uniques = Index(uniques)\n"
     ]
    }
   ],
   "source": [
    "for column in obj_cols:\n",
    "     train_test[column] = pd.factorize(train_test[column], sort=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086c88f7",
   "metadata": {},
   "source": [
    "To create some new columns that might compound the effects of the existing columns with higher impact on the xgb score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36eb99a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test['QualCondSum'] = train_test['OverallQual'] + train_test['OverallCond']\n",
    "train_test['RemodTime'] = train_test['YearRemodAdd'] - train_test['YearBuilt']\n",
    "train_test['BsmtFinTypeSF1'] = train_test['BsmtFinType1'] * train_test['BsmtFinSF1']\n",
    "train_test['TotalFlrSF'] = train_test['1stFlrSF'] + train_test['2ndFlrSF']\n",
    "train_test['TotalFinSF'] = train_test['GrLivArea'] + train_test['BsmtFinSF1']\n",
    "train_test['GarageCarArea'] = train_test['GarageArea'] * train_test['GarageCars']\n",
    "train_test['TotalSF'] = train_test['1stFlrSF'] + train_test['2ndFlrSF'] + train_test['TotalBsmtSF']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c5aaf2",
   "metadata": {},
   "source": [
    "To now eliminate the columns that have negative or zero influence on the xgb score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a8669c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test.drop(['Utilities','Street','TotRmsAbvGrd','3SsnPorch','YrSold','Exterior2nd','LotConfig',\n",
    "                              'HouseStyle','EnclosedPorch','WoodDeckSF','Foundation','RoofMatl','Electrical',\n",
    "                              'GarageType','LotFrontage','SaleType','MoSold','BsmtExposure','1stFlrSF',\n",
    "                              'BsmtFinSF1','Exterior1st','KitchenQual','TotalFlrSF'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a231025",
   "metadata": {},
   "source": [
    "To look at how many features have a skew above 0.5, since high skew can be an issue in regression analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96c88d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "skew_features = train_test.apply(lambda x: skew(x)).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7703e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_skew = skew_features[skew_features > 0.5]\n",
    "skew_index = high_skew.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9442b0d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MiscVal', 'PoolArea', 'LotArea', 'LowQualFinSF', 'Heating',\n",
       "       'Condition2', 'LandSlope', 'KitchenAbvGr', 'ScreenPorch',\n",
       "       'BsmtHalfBath', 'BsmtFinSF2', 'Condition1', 'OpenPorchSF', 'BldgType',\n",
       "       'RemodTime', 'MasVnrArea', 'RoofStyle', 'MSSubClass', 'GarageCarArea',\n",
       "       'GrLivArea', 'TotalFinSF', 'BsmtFinTypeSF1', 'TotalSF', '2ndFlrSF',\n",
       "       'BsmtQual', 'Fireplaces', 'HalfBath', 'BsmtFullBath', 'OverallCond'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skew_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d624c669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 29 numerical features with Skew > 0.5 :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MiscVal           21.947195\n",
       "PoolArea          16.898328\n",
       "LotArea           12.822431\n",
       "LowQualFinSF      12.088761\n",
       "Heating           12.078788\n",
       "Condition2        12.060093\n",
       "LandSlope          4.975157\n",
       "KitchenAbvGr       4.302254\n",
       "ScreenPorch        3.946694\n",
       "BsmtHalfBath       3.931594\n",
       "BsmtFinSF2         3.476562\n",
       "Condition1         2.983114\n",
       "OpenPorchSF        2.535114\n",
       "BldgType           2.192261\n",
       "RemodTime          2.063712\n",
       "MasVnrArea         1.556310\n",
       "RoofStyle          1.553307\n",
       "MSSubClass         1.375457\n",
       "GarageCarArea      1.296672\n",
       "GrLivArea          1.269358\n",
       "TotalFinSF         1.159630\n",
       "BsmtFinTypeSF1     0.932490\n",
       "TotalSF            0.922771\n",
       "2ndFlrSF           0.861675\n",
       "BsmtQual           0.796302\n",
       "Fireplaces         0.733495\n",
       "HalfBath           0.694566\n",
       "BsmtFullBath       0.624832\n",
       "OverallCond        0.570312\n",
       "HeatingQC          0.486656\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"There are {} numerical features with Skew > 0.5 :\".format(high_skew.shape[0]))\n",
    "skewness = pd.DataFrame({'Skew' :high_skew})\n",
    "skew_features.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9ecf2b",
   "metadata": {},
   "source": [
    "To normalize the features with skew above 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99f32924",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tompe\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:397: RuntimeWarning: divide by zero encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "for i in skew_index:\n",
    "    train_test[i] = np.log1p(train_test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48390e60",
   "metadata": {},
   "source": [
    "To create a column with the log of the SalePrice to match the evaluation process in the contest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77ad85f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test['LogSalePrice'] = train_test['SalePrice'].apply(np.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cbcb5e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    12.247694\n",
       "1    12.109011\n",
       "2    12.317167\n",
       "3    11.849398\n",
       "4    12.429216\n",
       "Name: LogSalePrice, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test['LogSalePrice'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ddaf56e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Condition1</th>\n",
       "      <th>Condition2</th>\n",
       "      <th>...</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>QualCondSum</th>\n",
       "      <th>RemodTime</th>\n",
       "      <th>BsmtFinTypeSF1</th>\n",
       "      <th>TotalFinSF</th>\n",
       "      <th>GarageCarArea</th>\n",
       "      <th>TotalSF</th>\n",
       "      <th>LogSalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4.110874</td>\n",
       "      <td>3</td>\n",
       "      <td>9.042040</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>208500.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.030410</td>\n",
       "      <td>7.706613</td>\n",
       "      <td>6.340359</td>\n",
       "      <td>7.586804</td>\n",
       "      <td>12.247694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>3</td>\n",
       "      <td>9.169623</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>181500.0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.183397</td>\n",
       "      <td>7.590347</td>\n",
       "      <td>6.003887</td>\n",
       "      <td>7.531552</td>\n",
       "      <td>12.109011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.110874</td>\n",
       "      <td>3</td>\n",
       "      <td>9.328212</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>223500.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>7.597396</td>\n",
       "      <td>7.658700</td>\n",
       "      <td>6.514713</td>\n",
       "      <td>7.646831</td>\n",
       "      <td>12.317167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.262680</td>\n",
       "      <td>3</td>\n",
       "      <td>9.164401</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>12</td>\n",
       "      <td>4.025352</td>\n",
       "      <td>6.364751</td>\n",
       "      <td>7.514255</td>\n",
       "      <td>7.002156</td>\n",
       "      <td>7.549083</td>\n",
       "      <td>11.849398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4.110874</td>\n",
       "      <td>3</td>\n",
       "      <td>9.565284</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>250000.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.942718</td>\n",
       "      <td>7.889084</td>\n",
       "      <td>7.303843</td>\n",
       "      <td>7.902118</td>\n",
       "      <td>12.429216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass  MSZoning   LotArea  LotShape  LandContour  LandSlope  \\\n",
       "0   1    4.110874         3  9.042040         3            3        0.0   \n",
       "1   2    3.044522         3  9.169623         3            3        0.0   \n",
       "2   3    4.110874         3  9.328212         0            3        0.0   \n",
       "3   4    4.262680         3  9.164401         0            3        0.0   \n",
       "4   5    4.110874         3  9.565284         0            3        0.0   \n",
       "\n",
       "   Neighborhood  Condition1  Condition2  ...  MiscVal  SaleCondition  \\\n",
       "0             5    1.098612    1.098612  ...      0.0              4   \n",
       "1            24    0.693147    1.098612  ...      0.0              4   \n",
       "2             5    1.098612    1.098612  ...      0.0              4   \n",
       "3             6    1.098612    1.098612  ...      0.0              0   \n",
       "4            15    1.098612    1.098612  ...      0.0              4   \n",
       "\n",
       "   SalePrice  QualCondSum  RemodTime  BsmtFinTypeSF1  TotalFinSF  \\\n",
       "0   208500.0           12   0.000000        8.030410    7.706613   \n",
       "1   181500.0           14   0.000000        8.183397    7.590347   \n",
       "2   223500.0           12   0.693147        7.597396    7.658700   \n",
       "3   140000.0           12   4.025352        6.364751    7.514255   \n",
       "4   250000.0           13   0.000000        7.942718    7.889084   \n",
       "\n",
       "   GarageCarArea   TotalSF  LogSalePrice  \n",
       "0       6.340359  7.586804     12.247694  \n",
       "1       6.003887  7.531552     12.109011  \n",
       "2       6.514713  7.646831     12.317167  \n",
       "3       7.002156  7.549083     11.849398  \n",
       "4       7.303843  7.902118     12.429216  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1baca8c9",
   "metadata": {},
   "source": [
    "To separate the train_test dataset back into the train and test datasets, identify the independent and dependent columns, and create the validation split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c5bba200",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_test[train_test['SalePrice'].notnull()].copy()\n",
    "test = train_test[train_test['SalePrice'].isnull()].drop(['SalePrice','LogSalePrice'],axis=1)\n",
    "X = train.drop(['SalePrice','LogSalePrice'],axis=1)\n",
    "y = train.LogSalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0fc4b112",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "476671cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = shuffle(X,y, random_state=42)\n",
    "X = X.reset_index(drop=True)\n",
    "y = y.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cb84d026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_cv(model,X,y):\n",
    "    rmse = np.sqrt(-cross_val_score(model, X, y, scoring=\"neg_mean_squared_error\", cv=6))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d96ccc11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13790232175471712\n"
     ]
    }
   ],
   "source": [
    "print(rmse_cv(xgb_model,X,y).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "971bed74",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = test[['Id']]\n",
    "submit = submit.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "307d593d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c0e70573",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_predict = xgb_model.predict(test)\n",
    "submit_predict = np.exp(submit_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0342d3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['SalePrice'] = submit_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "395cc685",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('submit_xgb_feature_eng.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6608dff0",
   "metadata": {},
   "source": [
    "Reducing feature skewness actually slightly increased the Kaggle score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2330e12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
