{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6b0e168",
   "metadata": {
    "papermill": {
     "duration": 0.013435,
     "end_time": "2023-09-01T05:42:57.460664",
     "exception": false,
     "start_time": "2023-09-01T05:42:57.447229",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Preparation and Text Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5ff0c6",
   "metadata": {
    "papermill": {
     "duration": 0.011958,
     "end_time": "2023-09-01T05:42:57.492390",
     "exception": false,
     "start_time": "2023-09-01T05:42:57.480432",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The starter notebook for this competition uses DistilBERT model from Keras NLP. So that will be used here with some basic cleaning up of the tweets and of situations where the targets differ for multiple version of the same tweet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b221ee46",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-09-01T05:42:57.518228Z",
     "iopub.status.busy": "2023-09-01T05:42:57.517779Z",
     "iopub.status.idle": "2023-09-01T05:43:25.638559Z",
     "shell.execute_reply": "2023-09-01T05:43:25.637128Z"
    },
    "papermill": {
     "duration": 28.137083,
     "end_time": "2023-09-01T05:43:25.641289",
     "exception": false,
     "start_time": "2023-09-01T05:42:57.504206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-core\r\n",
      "  Downloading keras_core-0.1.5-py3-none-any.whl (924 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m924.6/924.6 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from keras-core) (1.4.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from keras-core) (1.23.5)\r\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras-core) (13.4.2)\r\n",
      "Collecting namex (from keras-core)\r\n",
      "  Downloading namex-0.0.7-py3-none-any.whl (5.8 kB)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from keras-core) (3.9.0)\r\n",
      "Requirement already satisfied: dm-tree in /opt/conda/lib/python3.10/site-packages (from keras-core) (0.1.8)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras-core) (2.2.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras-core) (2.15.1)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras-core) (0.1.0)\r\n",
      "Installing collected packages: namex, keras-core\r\n",
      "Successfully installed keras-core-0.1.5 namex-0.0.7\r\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-core --upgrade\n",
    "!pip install -q keras-nlp --upgrade\n",
    "\n",
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e08f3a8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T05:43:25.670492Z",
     "iopub.status.busy": "2023-09-01T05:43:25.670147Z",
     "iopub.status.idle": "2023-09-01T05:43:44.669999Z",
     "shell.execute_reply": "2023-09-01T05:43:44.668433Z"
    },
    "papermill": {
     "duration": 19.016866,
     "end_time": "2023-09-01T05:43:44.672326",
     "exception": false,
     "start_time": "2023-09-01T05:43:25.655460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n",
      "TensorFlow version: 2.12.0\n",
      "KerasNLP version: 0.6.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "import keras_core as keras\n",
    "import keras_nlp\n",
    "\n",
    "import random as python_random\n",
    "import re\n",
    "import string\n",
    "import emoji\n",
    "import nltk\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"KerasNLP version:\", keras_nlp.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e4aa5c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T05:43:44.703696Z",
     "iopub.status.busy": "2023-09-01T05:43:44.703045Z",
     "iopub.status.idle": "2023-09-01T05:43:44.826526Z",
     "shell.execute_reply": "2023-09-01T05:43:44.825415Z"
    },
    "papermill": {
     "duration": 0.141618,
     "end_time": "2023-09-01T05:43:44.828945",
     "exception": false,
     "start_time": "2023-09-01T05:43:44.687327",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Shape = (7613, 5)\n",
      "Training Set Memory Usage = 0.29 MB\n",
      "Test Set Shape = (3263, 4)\n",
      "Test Set Memory Usage = 0.10 MB\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\")\n",
    "test = pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")\n",
    "\n",
    "print('Training Set Shape = {}'.format(train.shape))\n",
    "print('Training Set Memory Usage = {:.2f} MB'.format(train.memory_usage().sum() / 1024**2))\n",
    "print('Test Set Shape = {}'.format(test.shape))\n",
    "print('Test Set Memory Usage = {:.2f} MB'.format(test.memory_usage().sum() / 1024**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc7a882b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T05:43:44.858521Z",
     "iopub.status.busy": "2023-09-01T05:43:44.858192Z",
     "iopub.status.idle": "2023-09-01T05:43:44.877899Z",
     "shell.execute_reply": "2023-09-01T05:43:44.876144Z"
    },
    "papermill": {
     "duration": 0.038216,
     "end_time": "2023-09-01T05:43:44.881692",
     "exception": false,
     "start_time": "2023-09-01T05:43:44.843476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fec8dc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T05:43:44.911263Z",
     "iopub.status.busy": "2023-09-01T05:43:44.910986Z",
     "iopub.status.idle": "2023-09-01T05:43:44.920891Z",
     "shell.execute_reply": "2023-09-01T05:43:44.919878Z"
    },
    "papermill": {
     "duration": 0.027113,
     "end_time": "2023-09-01T05:43:44.923206",
     "exception": false,
     "start_time": "2023-09-01T05:43:44.896093",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09db22d0",
   "metadata": {
    "papermill": {
     "duration": 0.013564,
     "end_time": "2023-09-01T05:43:44.951921",
     "exception": false,
     "start_time": "2023-09-01T05:43:44.938357",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "A lot of the tweets in the dataset need to be cleaned up. Doing so should improve the results. In researching a way to clean up this text, the following Stack Overflow post was extremely helpful: https://stackoverflow.com/questions/64719706/cleaning-twitter-data-pandas-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3533ccb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T05:43:44.982605Z",
     "iopub.status.busy": "2023-09-01T05:43:44.981749Z",
     "iopub.status.idle": "2023-09-01T05:43:46.220676Z",
     "shell.execute_reply": "2023-09-01T05:43:46.219650Z"
    },
    "papermill": {
     "duration": 1.256771,
     "end_time": "2023-09-01T05:43:46.223373",
     "exception": false,
     "start_time": "2023-09-01T05:43:44.966602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_clean_tweets = []\n",
    "for tweet in train['text']:\n",
    "    tweet = re.sub(\"@[A-Za-z0-9]+\",\"\",tweet) #Remove @ sign\n",
    "    tweet = re.sub(r\"(?:\\@|http?\\://|https?\\://|www)\\S+\", \"\", tweet) #Remove http links\n",
    "    tweet = \" \".join(tweet.split())\n",
    "    emojis = emoji.distinct_emoji_list(tweet)\n",
    "    tweet = ''.join(c for c in tweet if c not in emojis) #Remove Emojis\n",
    "    tweet = tweet.replace(\"#\", \"\").replace(\"_\", \" \") #Remove hashtag sign but keep the text\n",
    "    #tweet = \" \".join(w for w in nltk.wordpunct_tokenize(tweet) \\\n",
    "         #if w.lower() in tweet or not w.isalpha())\n",
    "    train_clean_tweets.append(tweet)\n",
    "    \n",
    "train['clean_text'] = train_clean_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5e6cb91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T05:43:46.254580Z",
     "iopub.status.busy": "2023-09-01T05:43:46.253579Z",
     "iopub.status.idle": "2023-09-01T05:43:46.272635Z",
     "shell.execute_reply": "2023-09-01T05:43:46.271494Z"
    },
    "papermill": {
     "duration": 0.037926,
     "end_time": "2023-09-01T05:43:46.275897",
     "exception": false,
     "start_time": "2023-09-01T05:43:46.237971",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>Our Deeds are the Reason of this earthquake Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>13,000 people receive wildfires evacuation ord...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Just got sent this photo from Ruby Alaska as s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>1</td>\n",
       "      <td>ahrary The out of control wild fires in Calif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         1     NaN      NaN   \n",
       "1         4     NaN      NaN   \n",
       "2         5     NaN      NaN   \n",
       "3         6     NaN      NaN   \n",
       "4         7     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "7608  10869     NaN      NaN   \n",
       "7609  10870     NaN      NaN   \n",
       "7610  10871     NaN      NaN   \n",
       "7611  10872     NaN      NaN   \n",
       "7612  10873     NaN      NaN   \n",
       "\n",
       "                                                   text  target  \\\n",
       "0     Our Deeds are the Reason of this #earthquake M...       1   \n",
       "1                Forest fire near La Ronge Sask. Canada       1   \n",
       "2     All residents asked to 'shelter in place' are ...       1   \n",
       "3     13,000 people receive #wildfires evacuation or...       1   \n",
       "4     Just got sent this photo from Ruby #Alaska as ...       1   \n",
       "...                                                 ...     ...   \n",
       "7608  Two giant cranes holding a bridge collapse int...       1   \n",
       "7609  @aria_ahrary @TheTawniest The out of control w...       1   \n",
       "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1   \n",
       "7611  Police investigating after an e-bike collided ...       1   \n",
       "7612  The Latest: More Homes Razed by Northern Calif...       1   \n",
       "\n",
       "                                             clean_text  \n",
       "0     Our Deeds are the Reason of this earthquake Ma...  \n",
       "1                Forest fire near La Ronge Sask. Canada  \n",
       "2     All residents asked to 'shelter in place' are ...  \n",
       "3     13,000 people receive wildfires evacuation ord...  \n",
       "4     Just got sent this photo from Ruby Alaska as s...  \n",
       "...                                                 ...  \n",
       "7608  Two giant cranes holding a bridge collapse int...  \n",
       "7609   ahrary The out of control wild fires in Calif...  \n",
       "7610         M1.94 [01:04 UTC]?5km S of Volcano Hawaii.  \n",
       "7611  Police investigating after an e-bike collided ...  \n",
       "7612  The Latest: More Homes Razed by Northern Calif...  \n",
       "\n",
       "[7613 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a82462c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T05:43:46.307522Z",
     "iopub.status.busy": "2023-09-01T05:43:46.307238Z",
     "iopub.status.idle": "2023-09-01T05:43:46.856623Z",
     "shell.execute_reply": "2023-09-01T05:43:46.855621Z"
    },
    "papermill": {
     "duration": 0.567355,
     "end_time": "2023-09-01T05:43:46.859267",
     "exception": false,
     "start_time": "2023-09-01T05:43:46.291912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_clean_tweets = []\n",
    "for tweet in test['text']:\n",
    "    tweet = re.sub(\"@[A-Za-z0-9]+\",\"\",tweet) #Remove @ sign\n",
    "    tweet = re.sub(r\"(?:\\@|http?\\://|https?\\://|www)\\S+\", \"\", tweet) #Remove http links\n",
    "    tweet = \" \".join(tweet.split())\n",
    "    emojis = emoji.distinct_emoji_list(tweet)\n",
    "    tweet = ''.join(c for c in tweet if c not in emojis) #Remove Emojis\n",
    "    tweet = tweet.replace(\"#\", \"\").replace(\"_\", \" \") #Remove hashtag sign but keep the text\n",
    "    #tweet = \" \".join(w for w in nltk.wordpunct_tokenize(tweet) \\\n",
    "         #if w.lower() in tweet or not w.isalpha())\n",
    "    test_clean_tweets.append(tweet)\n",
    "    \n",
    "test['clean_text'] = test_clean_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c5f3b4",
   "metadata": {
    "papermill": {
     "duration": 0.014752,
     "end_time": "2023-09-01T05:43:46.889914",
     "exception": false,
     "start_time": "2023-09-01T05:43:46.875162",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Varying Target Values for the Same Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461d8fb3",
   "metadata": {
    "papermill": {
     "duration": 0.0146,
     "end_time": "2023-09-01T05:43:46.919491",
     "exception": false,
     "start_time": "2023-09-01T05:43:46.904891",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Looking at the number of unique values in each column of the train dataset it shows that there are 7613 total columns, but only 6922 of the input columns are unique, which is a total of 791 rows. That is a lot. The question whether a unique input value with many occurances are all labeled with the same target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4b84607",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T05:43:46.951670Z",
     "iopub.status.busy": "2023-09-01T05:43:46.951037Z",
     "iopub.status.idle": "2023-09-01T05:43:46.973129Z",
     "shell.execute_reply": "2023-09-01T05:43:46.972054Z"
    },
    "papermill": {
     "duration": 0.04057,
     "end_time": "2023-09-01T05:43:46.975364",
     "exception": false,
     "start_time": "2023-09-01T05:43:46.934794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id            7613\n",
       "keyword        221\n",
       "location      3341\n",
       "text          7503\n",
       "target           2\n",
       "clean_text    6922\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baea2337",
   "metadata": {
    "papermill": {
     "duration": 0.014986,
     "end_time": "2023-09-01T05:43:47.005418",
     "exception": false,
     "start_time": "2023-09-01T05:43:46.990432",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "To explore this potential labeling issue, a new column called 'unique_input' is created to be able to look at some of the larger occurances of unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95796090",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T05:43:47.037859Z",
     "iopub.status.busy": "2023-09-01T05:43:47.036858Z",
     "iopub.status.idle": "2023-09-01T05:43:47.045713Z",
     "shell.execute_reply": "2023-09-01T05:43:47.044849Z"
    },
    "papermill": {
     "duration": 0.027731,
     "end_time": "2023-09-01T05:43:47.047878",
     "exception": false,
     "start_time": "2023-09-01T05:43:47.020147",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train['unique_text'] = pd.factorize(train['clean_text'])[0] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c708c77d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T05:43:47.079723Z",
     "iopub.status.busy": "2023-09-01T05:43:47.078887Z",
     "iopub.status.idle": "2023-09-01T05:43:47.094984Z",
     "shell.execute_reply": "2023-09-01T05:43:47.093884Z"
    },
    "papermill": {
     "duration": 0.034452,
     "end_time": "2023-09-01T05:43:47.097401",
     "exception": false,
     "start_time": "2023-09-01T05:43:47.062949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>unique_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>Our Deeds are the Reason of this earthquake Ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>13,000 people receive wildfires evacuation ord...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Just got sent this photo from Ruby Alaska as s...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>1</td>\n",
       "      <td>ahrary The out of control wild fires in Calif...</td>\n",
       "      <td>6667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii.</td>\n",
       "      <td>6497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>5102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         1     NaN      NaN   \n",
       "1         4     NaN      NaN   \n",
       "2         5     NaN      NaN   \n",
       "3         6     NaN      NaN   \n",
       "4         7     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "7608  10869     NaN      NaN   \n",
       "7609  10870     NaN      NaN   \n",
       "7610  10871     NaN      NaN   \n",
       "7611  10872     NaN      NaN   \n",
       "7612  10873     NaN      NaN   \n",
       "\n",
       "                                                   text  target  \\\n",
       "0     Our Deeds are the Reason of this #earthquake M...       1   \n",
       "1                Forest fire near La Ronge Sask. Canada       1   \n",
       "2     All residents asked to 'shelter in place' are ...       1   \n",
       "3     13,000 people receive #wildfires evacuation or...       1   \n",
       "4     Just got sent this photo from Ruby #Alaska as ...       1   \n",
       "...                                                 ...     ...   \n",
       "7608  Two giant cranes holding a bridge collapse int...       1   \n",
       "7609  @aria_ahrary @TheTawniest The out of control w...       1   \n",
       "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1   \n",
       "7611  Police investigating after an e-bike collided ...       1   \n",
       "7612  The Latest: More Homes Razed by Northern Calif...       1   \n",
       "\n",
       "                                             clean_text  unique_text  \n",
       "0     Our Deeds are the Reason of this earthquake Ma...            1  \n",
       "1                Forest fire near La Ronge Sask. Canada            2  \n",
       "2     All residents asked to 'shelter in place' are ...            3  \n",
       "3     13,000 people receive wildfires evacuation ord...            4  \n",
       "4     Just got sent this photo from Ruby Alaska as s...            5  \n",
       "...                                                 ...          ...  \n",
       "7608  Two giant cranes holding a bridge collapse int...         1080  \n",
       "7609   ahrary The out of control wild fires in Calif...         6667  \n",
       "7610         M1.94 [01:04 UTC]?5km S of Volcano Hawaii.         6497  \n",
       "7611  Police investigating after an e-bike collided ...         1573  \n",
       "7612  The Latest: More Homes Razed by Northern Calif...         5102  \n",
       "\n",
       "[7613 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7e8b04",
   "metadata": {
    "papermill": {
     "duration": 0.015713,
     "end_time": "2023-09-01T05:43:47.130964",
     "exception": false,
     "start_time": "2023-09-01T05:43:47.115251",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Looking at the top five unique occurances, only the 4th one, 4061, had variations in the target values. It doesn't appear to be a disaster, but 5 out of 17 occurances were coded as a disaster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5103f645",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T05:43:47.165060Z",
     "iopub.status.busy": "2023-09-01T05:43:47.164672Z",
     "iopub.status.idle": "2023-09-01T05:43:47.179257Z",
     "shell.execute_reply": "2023-09-01T05:43:47.178246Z"
    },
    "papermill": {
     "duration": 0.034466,
     "end_time": "2023-09-01T05:43:47.181454",
     "exception": false,
     "start_time": "2023-09-01T05:43:47.146988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5351    24\n",
       "6848    20\n",
       "4862    19\n",
       "4061    17\n",
       "447     15\n",
       "Name: unique_text, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['unique_text'].value_counts().nlargest(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "504e531a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T05:43:47.214254Z",
     "iopub.status.busy": "2023-09-01T05:43:47.213364Z",
     "iopub.status.idle": "2023-09-01T05:43:47.224248Z",
     "shell.execute_reply": "2023-09-01T05:43:47.223069Z"
    },
    "papermill": {
     "duration": 0.031282,
     "end_time": "2023-09-01T05:43:47.228195",
     "exception": false,
     "start_time": "2023-09-01T05:43:47.196913",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id    keyword             location  \\\n",
      "4391  6243  hijacking    perth, australia    \n",
      "4392  6244  hijacking             Mongolia   \n",
      "4393  6245  hijacking  brisbane, australia   \n",
      "4394  6246  hijacking                China   \n",
      "4396  6248  hijacking  Chiyoda Ward, Tokyo   \n",
      "4397  6253  hijacking                 rome   \n",
      "4399  6255  hijacking         EastCarolina   \n",
      "4400  6256  hijacking               Brazil   \n",
      "4403  6259  hijacking                  NaN   \n",
      "4404  6261  hijacking               France   \n",
      "4405  6262  hijacking                  NaN   \n",
      "4407  6265  hijacking                tokyo   \n",
      "4408  6267  hijacking                china   \n",
      "4412  6272  hijacking               Brazil   \n",
      "4414  6274  hijacking                  NaN   \n",
      "4415  6276  hijacking                Japan   \n",
      "4420  6283  hijacking                  NaN   \n",
      "\n",
      "                                                   text  target  \\\n",
      "4391  #hot  Funtenna: hijacking computers to send da...       0   \n",
      "4392  #hot  Funtenna: hijacking computers to send da...       1   \n",
      "4393  #hot  Funtenna: hijacking computers to send da...       0   \n",
      "4394  #hot  Funtenna: hijacking computers to send da...       0   \n",
      "4396  #hot  Funtenna: hijacking computers to send da...       0   \n",
      "4397  #hot  Funtenna: hijacking computers to send da...       0   \n",
      "4399  #hot  Funtenna: hijacking computers to send da...       0   \n",
      "4400  #hot  Funtenna: hijacking computers to send da...       0   \n",
      "4403  #hot  Funtenna: hijacking computers to send da...       1   \n",
      "4404  #hot  Funtenna: hijacking computers to send da...       0   \n",
      "4405  #hot  Funtenna: hijacking computers to send da...       0   \n",
      "4407  #hot  Funtenna: hijacking computers to send da...       0   \n",
      "4408  #hot  Funtenna: hijacking computers to send da...       0   \n",
      "4412  #hot  Funtenna: hijacking computers to send da...       0   \n",
      "4414  #hot  Funtenna: hijacking computers to send da...       1   \n",
      "4415  #hot  Funtenna: hijacking computers to send da...       1   \n",
      "4420  #hot  Funtenna: hijacking computers to send da...       1   \n",
      "\n",
      "                                             clean_text  unique_text  \n",
      "4391  hot Funtenna: hijacking computers to send data...         4061  \n",
      "4392  hot Funtenna: hijacking computers to send data...         4061  \n",
      "4393  hot Funtenna: hijacking computers to send data...         4061  \n",
      "4394  hot Funtenna: hijacking computers to send data...         4061  \n",
      "4396  hot Funtenna: hijacking computers to send data...         4061  \n",
      "4397  hot Funtenna: hijacking computers to send data...         4061  \n",
      "4399  hot Funtenna: hijacking computers to send data...         4061  \n",
      "4400  hot Funtenna: hijacking computers to send data...         4061  \n",
      "4403  hot Funtenna: hijacking computers to send data...         4061  \n",
      "4404  hot Funtenna: hijacking computers to send data...         4061  \n",
      "4405  hot Funtenna: hijacking computers to send data...         4061  \n",
      "4407  hot Funtenna: hijacking computers to send data...         4061  \n",
      "4408  hot Funtenna: hijacking computers to send data...         4061  \n",
      "4412  hot Funtenna: hijacking computers to send data...         4061  \n",
      "4414  hot Funtenna: hijacking computers to send data...         4061  \n",
      "4415  hot Funtenna: hijacking computers to send data...         4061  \n",
      "4420  hot Funtenna: hijacking computers to send data...         4061  \n"
     ]
    }
   ],
   "source": [
    "print(train.loc[train['unique_text'] == 4061])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014a6f46",
   "metadata": {
    "papermill": {
     "duration": 0.015404,
     "end_time": "2023-09-01T05:43:47.260671",
     "exception": false,
     "start_time": "2023-09-01T05:43:47.245267",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "There are 314 tweets that that are repeated more than once. There is a pretty good chance that some more of these may have different target codes for the same text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f72ac812",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T05:43:47.293868Z",
     "iopub.status.busy": "2023-09-01T05:43:47.293540Z",
     "iopub.status.idle": "2023-09-01T05:43:47.303542Z",
     "shell.execute_reply": "2023-09-01T05:43:47.302531Z"
    },
    "papermill": {
     "duration": 0.029111,
     "end_time": "2023-09-01T05:43:47.305772",
     "exception": false,
     "start_time": "2023-09-01T05:43:47.276661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "314"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['unique_text'].value_counts().ne(1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dc2f5f",
   "metadata": {
    "papermill": {
     "duration": 0.015483,
     "end_time": "2023-09-01T05:43:47.336265",
     "exception": false,
     "start_time": "2023-09-01T05:43:47.320782",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "One way to correct this potential problem is to use the target mode for a set of duplicate tweets and change any targets that don't match to this mode value. For instance, in the example above for number 4061, the mode would be 0 and the 5 values that are not 0 would be changed to 0. \n",
    "\n",
    "To start this process a new dataframe is created to capture the mode for each unique tweet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cdd79fd0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T05:43:47.378328Z",
     "iopub.status.busy": "2023-09-01T05:43:47.377416Z",
     "iopub.status.idle": "2023-09-01T05:43:49.431313Z",
     "shell.execute_reply": "2023-09-01T05:43:49.430325Z"
    },
    "papermill": {
     "duration": 2.081754,
     "end_time": "2023-09-01T05:43:49.433702",
     "exception": false,
     "start_time": "2023-09-01T05:43:47.351948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_unique_mode = train.groupby('unique_text').agg({'target': lambda x: x.value_counts().index[0]}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8f6ab7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T05:43:49.465935Z",
     "iopub.status.busy": "2023-09-01T05:43:49.465609Z",
     "iopub.status.idle": "2023-09-01T05:43:49.477522Z",
     "shell.execute_reply": "2023-09-01T05:43:49.476518Z"
    },
    "papermill": {
     "duration": 0.030147,
     "end_time": "2023-09-01T05:43:49.479728",
     "exception": false,
     "start_time": "2023-09-01T05:43:49.449581",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6917</th>\n",
       "      <td>6918</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6918</th>\n",
       "      <td>6919</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6919</th>\n",
       "      <td>6920</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6920</th>\n",
       "      <td>6921</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6921</th>\n",
       "      <td>6922</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6922 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      unique_text  target\n",
       "0               1       1\n",
       "1               2       1\n",
       "2               3       1\n",
       "3               4       1\n",
       "4               5       1\n",
       "...           ...     ...\n",
       "6917         6918       1\n",
       "6918         6919       1\n",
       "6919         6920       1\n",
       "6920         6921       1\n",
       "6921         6922       1\n",
       "\n",
       "[6922 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_unique_mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870e5149",
   "metadata": {
    "papermill": {
     "duration": 0.015298,
     "end_time": "2023-09-01T05:43:49.512311",
     "exception": false,
     "start_time": "2023-09-01T05:43:49.497013",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "These mode values are then added as a new column called 'new_target' in the train dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "965ad045",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T05:43:49.545354Z",
     "iopub.status.busy": "2023-09-01T05:43:49.544564Z",
     "iopub.status.idle": "2023-09-01T05:43:49.552357Z",
     "shell.execute_reply": "2023-09-01T05:43:49.551520Z"
    },
    "papermill": {
     "duration": 0.026056,
     "end_time": "2023-09-01T05:43:49.554300",
     "exception": false,
     "start_time": "2023-09-01T05:43:49.528244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train['new_target'] = train['unique_text'].map(train_unique_mode.set_index('unique_text')['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d5408e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T05:43:49.587151Z",
     "iopub.status.busy": "2023-09-01T05:43:49.586323Z",
     "iopub.status.idle": "2023-09-01T05:43:49.603105Z",
     "shell.execute_reply": "2023-09-01T05:43:49.601882Z"
    },
    "papermill": {
     "duration": 0.036128,
     "end_time": "2023-09-01T05:43:49.606019",
     "exception": false,
     "start_time": "2023-09-01T05:43:49.569891",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>unique_text</th>\n",
       "      <th>new_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>Our Deeds are the Reason of this earthquake Ma...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>13,000 people receive wildfires evacuation ord...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Just got sent this photo from Ruby Alaska as s...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#RockyFire Update =&gt; California Hwy. 20 closed...</td>\n",
       "      <td>1</td>\n",
       "      <td>RockyFire Update =&gt; California Hwy. 20 closed ...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#flood #disaster Heavy rain causes flash flood...</td>\n",
       "      <td>1</td>\n",
       "      <td>flood disaster Heavy rain causes flash floodin...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm on top of the hill and I can see a fire in...</td>\n",
       "      <td>1</td>\n",
       "      <td>I'm on top of the hill and I can see a fire in...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>There's an emergency evacuation happening now ...</td>\n",
       "      <td>1</td>\n",
       "      <td>There's an emergency evacuation happening now ...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm afraid that the tornado is coming to our a...</td>\n",
       "      <td>1</td>\n",
       "      <td>I'm afraid that the tornado is coming to our a...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Three people died from the heat wave so far</td>\n",
       "      <td>1</td>\n",
       "      <td>Three people died from the heat wave so far</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Haha South Tampa is getting flooded hah- WAIT ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Haha South Tampa is getting flooded hah- WAIT ...</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#raining #flooding #Florida #TampaBay #Tampa 1...</td>\n",
       "      <td>1</td>\n",
       "      <td>raining flooding Florida TampaBay Tampa 18 or ...</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#Flood in Bago Myanmar #We arrived Bago</td>\n",
       "      <td>1</td>\n",
       "      <td>Flood in Bago Myanmar We arrived Bago</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Damage to school bus on 80 in multi car crash ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Damage to school bus on 80 in multi car crash ...</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What's up man?</td>\n",
       "      <td>0</td>\n",
       "      <td>What's up man?</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I love fruits</td>\n",
       "      <td>0</td>\n",
       "      <td>I love fruits</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Summer is lovely</td>\n",
       "      <td>0</td>\n",
       "      <td>Summer is lovely</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My car is so fast</td>\n",
       "      <td>0</td>\n",
       "      <td>My car is so fast</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What a goooooooaaaaaal!!!!!!</td>\n",
       "      <td>0</td>\n",
       "      <td>What a goooooooaaaaaal!!!!!!</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>this is ridiculous....</td>\n",
       "      <td>0</td>\n",
       "      <td>this is ridiculous....</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>London is cool ;)</td>\n",
       "      <td>0</td>\n",
       "      <td>London is cool ;)</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Love skiing</td>\n",
       "      <td>0</td>\n",
       "      <td>Love skiing</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What a wonderful day!</td>\n",
       "      <td>0</td>\n",
       "      <td>What a wonderful day!</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LOOOOOOL</td>\n",
       "      <td>0</td>\n",
       "      <td>LOOOOOOL</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id keyword location                                               text  \\\n",
       "0    1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1    4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2    5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3    6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4    7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "5    8     NaN      NaN  #RockyFire Update => California Hwy. 20 closed...   \n",
       "6   10     NaN      NaN  #flood #disaster Heavy rain causes flash flood...   \n",
       "7   13     NaN      NaN  I'm on top of the hill and I can see a fire in...   \n",
       "8   14     NaN      NaN  There's an emergency evacuation happening now ...   \n",
       "9   15     NaN      NaN  I'm afraid that the tornado is coming to our a...   \n",
       "10  16     NaN      NaN        Three people died from the heat wave so far   \n",
       "11  17     NaN      NaN  Haha South Tampa is getting flooded hah- WAIT ...   \n",
       "12  18     NaN      NaN  #raining #flooding #Florida #TampaBay #Tampa 1...   \n",
       "13  19     NaN      NaN            #Flood in Bago Myanmar #We arrived Bago   \n",
       "14  20     NaN      NaN  Damage to school bus on 80 in multi car crash ...   \n",
       "15  23     NaN      NaN                                     What's up man?   \n",
       "16  24     NaN      NaN                                      I love fruits   \n",
       "17  25     NaN      NaN                                   Summer is lovely   \n",
       "18  26     NaN      NaN                                  My car is so fast   \n",
       "19  28     NaN      NaN                       What a goooooooaaaaaal!!!!!!   \n",
       "20  31     NaN      NaN                             this is ridiculous....   \n",
       "21  32     NaN      NaN                                  London is cool ;)   \n",
       "22  33     NaN      NaN                                        Love skiing   \n",
       "23  34     NaN      NaN                              What a wonderful day!   \n",
       "24  36     NaN      NaN                                           LOOOOOOL   \n",
       "\n",
       "    target                                         clean_text  unique_text  \\\n",
       "0        1  Our Deeds are the Reason of this earthquake Ma...            1   \n",
       "1        1             Forest fire near La Ronge Sask. Canada            2   \n",
       "2        1  All residents asked to 'shelter in place' are ...            3   \n",
       "3        1  13,000 people receive wildfires evacuation ord...            4   \n",
       "4        1  Just got sent this photo from Ruby Alaska as s...            5   \n",
       "5        1  RockyFire Update => California Hwy. 20 closed ...            6   \n",
       "6        1  flood disaster Heavy rain causes flash floodin...            7   \n",
       "7        1  I'm on top of the hill and I can see a fire in...            8   \n",
       "8        1  There's an emergency evacuation happening now ...            9   \n",
       "9        1  I'm afraid that the tornado is coming to our a...           10   \n",
       "10       1        Three people died from the heat wave so far           11   \n",
       "11       1  Haha South Tampa is getting flooded hah- WAIT ...           12   \n",
       "12       1  raining flooding Florida TampaBay Tampa 18 or ...           13   \n",
       "13       1              Flood in Bago Myanmar We arrived Bago           14   \n",
       "14       1  Damage to school bus on 80 in multi car crash ...           15   \n",
       "15       0                                     What's up man?           16   \n",
       "16       0                                      I love fruits           17   \n",
       "17       0                                   Summer is lovely           18   \n",
       "18       0                                  My car is so fast           19   \n",
       "19       0                       What a goooooooaaaaaal!!!!!!           20   \n",
       "20       0                             this is ridiculous....           21   \n",
       "21       0                                  London is cool ;)           22   \n",
       "22       0                                        Love skiing           23   \n",
       "23       0                              What a wonderful day!           24   \n",
       "24       0                                           LOOOOOOL           25   \n",
       "\n",
       "    new_target  \n",
       "0            1  \n",
       "1            1  \n",
       "2            1  \n",
       "3            1  \n",
       "4            1  \n",
       "5            1  \n",
       "6            1  \n",
       "7            1  \n",
       "8            1  \n",
       "9            1  \n",
       "10           1  \n",
       "11           1  \n",
       "12           1  \n",
       "13           1  \n",
       "14           1  \n",
       "15           0  \n",
       "16           0  \n",
       "17           0  \n",
       "18           0  \n",
       "19           0  \n",
       "20           0  \n",
       "21           0  \n",
       "22           0  \n",
       "23           0  \n",
       "24           0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c37e62",
   "metadata": {
    "papermill": {
     "duration": 0.016463,
     "end_time": "2023-09-01T05:43:49.640742",
     "exception": false,
     "start_time": "2023-09-01T05:43:49.624279",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "It looks like there are 89 rows where the new target is not equal to the original target, which means 89 rows were changed based on looking at the mode of unique tweets with more than one occurance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec2fe075",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T05:43:49.674834Z",
     "iopub.status.busy": "2023-09-01T05:43:49.674134Z",
     "iopub.status.idle": "2023-09-01T05:43:49.687232Z",
     "shell.execute_reply": "2023-09-01T05:43:49.686038Z"
    },
    "papermill": {
     "duration": 0.033086,
     "end_time": "2023-09-01T05:43:49.690020",
     "exception": false,
     "start_time": "2023-09-01T05:43:49.656934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train.query('new_target != target'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b76f4a5",
   "metadata": {
    "papermill": {
     "duration": 0.017358,
     "end_time": "2023-09-01T05:43:49.725662",
     "exception": false,
     "start_time": "2023-09-01T05:43:49.708304",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preparing to Use the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ca44ed",
   "metadata": {
    "papermill": {
     "duration": 0.018712,
     "end_time": "2023-09-01T05:43:49.761152",
     "exception": false,
     "start_time": "2023-09-01T05:43:49.742440",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The parameters from the starter notebook are used here and an 80/20 validation split is performed below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15fc8b6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T05:43:49.795783Z",
     "iopub.status.busy": "2023-09-01T05:43:49.795451Z",
     "iopub.status.idle": "2023-09-01T05:43:49.801085Z",
     "shell.execute_reply": "2023-09-01T05:43:49.800023Z"
    },
    "papermill": {
     "duration": 0.025857,
     "end_time": "2023-09-01T05:43:49.803223",
     "exception": false,
     "start_time": "2023-09-01T05:43:49.777366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "NUM_TRAINING_EXAMPLES = train.shape[0]\n",
    "TRAIN_SPLIT = 0.8\n",
    "VAL_SPLIT = 0.2\n",
    "STEPS_PER_EPOCH = int(NUM_TRAINING_EXAMPLES)*TRAIN_SPLIT // BATCH_SIZE\n",
    "\n",
    "EPOCHS = 2\n",
    "AUTO = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82a21440",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T05:43:49.837279Z",
     "iopub.status.busy": "2023-09-01T05:43:49.836972Z",
     "iopub.status.idle": "2023-09-01T05:43:49.846220Z",
     "shell.execute_reply": "2023-09-01T05:43:49.845410Z"
    },
    "papermill": {
     "duration": 0.028813,
     "end_time": "2023-09-01T05:43:49.848246",
     "exception": false,
     "start_time": "2023-09-01T05:43:49.819433",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = train[\"clean_text\"]\n",
    "y = train[\"new_target\"]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=VAL_SPLIT, random_state=42)\n",
    "\n",
    "X_test = test[\"clean_text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1597ac1",
   "metadata": {
    "papermill": {
     "duration": 0.016108,
     "end_time": "2023-09-01T05:43:49.880437",
     "exception": false,
     "start_time": "2023-09-01T05:43:49.864329",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "To ensure the results are the same for multiple iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1540fe2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T05:43:49.916004Z",
     "iopub.status.busy": "2023-09-01T05:43:49.915043Z",
     "iopub.status.idle": "2023-09-01T05:43:49.920507Z",
     "shell.execute_reply": "2023-09-01T05:43:49.919593Z"
    },
    "papermill": {
     "duration": 0.02526,
     "end_time": "2023-09-01T05:43:49.922667",
     "exception": false,
     "start_time": "2023-09-01T05:43:49.897407",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reset_seeds():\n",
    "   np.random.seed(42) \n",
    "   python_random.seed(42)\n",
    "   tf.random.set_seed(42)\n",
    "\n",
    "reset_seeds() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ba80f4",
   "metadata": {
    "papermill": {
     "duration": 0.016571,
     "end_time": "2023-09-01T05:43:49.955700",
     "exception": false,
     "start_time": "2023-09-01T05:43:49.939129",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Running the Model\n",
    "\n",
    "Text inputs need to be transformed to numeric token ids and arranged in several Tensors before being input to BERT.\n",
    "\n",
    "The BertClassifier model can be configured with a preprocessor layer, in which case it will automatically apply preprocessing to raw inputs during fit(), predict(), and evaluate(). This is done by default when creating the model with from_preset().\n",
    "\n",
    "The DistilBERT model that is chosen learns a distilled (approximate) version of BERT, retaining 97% performance but using only half the number of parameters ([paper](https://arxiv.org/abs/1910.01108)). \n",
    "\n",
    "It has 40% less parameters than bert-base-uncased, runs 60% faster while preserving over 95% of BERT’s performances as measured on the GLUE language understanding benchmark.\n",
    "\n",
    "Specifically, it doesn't have token-type embeddings, pooler and retains only half of the layers from Google's BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e50fbe98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T05:43:49.989741Z",
     "iopub.status.busy": "2023-09-01T05:43:49.989447Z",
     "iopub.status.idle": "2023-09-01T05:43:59.621882Z",
     "shell.execute_reply": "2023-09-01T05:43:59.620878Z"
    },
    "papermill": {
     "duration": 9.652147,
     "end_time": "2023-09-01T05:43:59.624139",
     "exception": false,
     "start_time": "2023-09-01T05:43:49.971992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-nlp/models/distil_bert_base_en_uncased/v1/vocab.txt\n",
      "\u001b[1m231508/231508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step       \n",
      "Downloading data from https://storage.googleapis.com/keras-nlp/models/distil_bert_base_en_uncased/v1/model.h5\n",
      "\u001b[1m265570304/265570304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"preprocessor_4_tweets\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mPreprocessor: \"preprocessor_4_tweets\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Tokenizer (type)                                   </span>┃<span style=\"font-weight: bold\">                                             Vocab # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ distil_bert_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DistilBertTokenizer</span>)        │                                              <span style=\"color: #00af00; text-decoration-color: #00af00\">30,522</span> │\n",
       "└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mTokenizer (type)                                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                            Vocab #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ distil_bert_tokenizer (\u001b[38;5;33mDistilBertTokenizer\u001b[0m)        │                                              \u001b[38;5;34m30,522\u001b[0m │\n",
       "└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"distil_bert_classifier\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"distil_bert_classifier\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">     Param # </span>┃<span style=\"font-weight: bold\"> Connected to                   </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
       "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
       "│ distil_bert_backbone          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)         │  <span style=\"color: #00af00; text-decoration-color: #00af00\">66,362,880</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DistilBertBackbone</span>)          │                           │             │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
       "│ get_item (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ distil_bert_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
       "│ pooled_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)               │     <span style=\"color: #00af00; text-decoration-color: #00af00\">590,592</span> │ get_item[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                 │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
       "│ classifier_dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ pooled_dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
       "│ logits (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,538</span> │ classifier_dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────┴────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m    Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to                  \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │           \u001b[38;5;34m0\u001b[0m │ -                              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
       "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │           \u001b[38;5;34m0\u001b[0m │ -                              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
       "│ distil_bert_backbone          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)         │  \u001b[38;5;34m66,362,880\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],            │\n",
       "│ (\u001b[38;5;33mDistilBertBackbone\u001b[0m)          │                           │             │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
       "│ get_item (\u001b[38;5;33mGetItem\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)               │           \u001b[38;5;34m0\u001b[0m │ distil_bert_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
       "│ pooled_dense (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)               │     \u001b[38;5;34m590,592\u001b[0m │ get_item[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                 │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
       "│ classifier_dropout (\u001b[38;5;33mDropout\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)               │           \u001b[38;5;34m0\u001b[0m │ pooled_dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
       "│ logits (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                 │       \u001b[38;5;34m1,538\u001b[0m │ classifier_dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────┴────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">66,955,010</span> (255.41 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m66,955,010\u001b[0m (255.41 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">66,955,010</span> (255.41 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m66,955,010\u001b[0m (255.41 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load a DistilBERT model.\n",
    "preset= \"distil_bert_base_en_uncased\"\n",
    "\n",
    "# Use a shorter sequence length.\n",
    "preprocessor = keras_nlp.models.DistilBertPreprocessor.from_preset(preset,\n",
    "                                                                   sequence_length=160,\n",
    "                                                                   name=\"preprocessor_4_tweets\"\n",
    "                                                                  )\n",
    "\n",
    "# Pretrained classifier.\n",
    "classifier = keras_nlp.models.DistilBertClassifier.from_preset(preset,\n",
    "                                                               preprocessor = preprocessor, \n",
    "                                                               num_classes=2)\n",
    "\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0cada331",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T05:43:59.667120Z",
     "iopub.status.busy": "2023-09-01T05:43:59.666765Z",
     "iopub.status.idle": "2023-09-01T05:49:01.839816Z",
     "shell.execute_reply": "2023-09-01T05:49:01.838540Z"
    },
    "papermill": {
     "duration": 302.240265,
     "end_time": "2023-09-01T05:49:01.885706",
     "exception": false,
     "start_time": "2023-09-01T05:43:59.645441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 606ms/step - accuracy: 0.7374 - loss: 0.5479 - val_accuracy: 0.8562 - val_loss: 0.3668\n",
      "Epoch 2/2\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 629ms/step - accuracy: 0.8535 - loss: 0.3619 - val_accuracy: 0.8628 - val_loss: 0.3530\n"
     ]
    }
   ],
   "source": [
    "# Compile\n",
    "classifier.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), #'binary_crossentropy',\n",
    "    optimizer=keras.optimizers.Adam(1e-5),\n",
    "    metrics= [\"accuracy\"]  \n",
    ")\n",
    "\n",
    "# Fit\n",
    "history = classifier.fit(x=X_train,\n",
    "                         y=y_train,\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         epochs=EPOCHS, \n",
    "                         validation_data=(X_val, y_val)\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a73635e",
   "metadata": {
    "papermill": {
     "duration": 0.049559,
     "end_time": "2023-09-01T05:49:01.986075",
     "exception": false,
     "start_time": "2023-09-01T05:49:01.936516",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7348c0ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T05:49:02.090030Z",
     "iopub.status.busy": "2023-09-01T05:49:02.089622Z",
     "iopub.status.idle": "2023-09-01T05:49:02.122146Z",
     "shell.execute_reply": "2023-09-01T05:49:02.121045Z"
    },
    "papermill": {
     "duration": 0.087472,
     "end_time": "2023-09-01T05:49:02.124289",
     "exception": false,
     "start_time": "2023-09-01T05:49:02.036817",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reset_seeds():\n",
    "   np.random.seed(42) \n",
    "   python_random.seed(42)\n",
    "   tf.random.set_seed(42)\n",
    "\n",
    "reset_seeds() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c22d656d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T05:49:02.232634Z",
     "iopub.status.busy": "2023-09-01T05:49:02.232269Z",
     "iopub.status.idle": "2023-09-01T05:49:02.264875Z",
     "shell.execute_reply": "2023-09-01T05:49:02.263863Z"
    },
    "papermill": {
     "duration": 0.089036,
     "end_time": "2023-09-01T05:49:02.267454",
     "exception": false,
     "start_time": "2023-09-01T05:49:02.178418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   0       0\n",
       "1   2       0\n",
       "2   3       0\n",
       "3   9       0\n",
       "4  11       0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission = pd.read_csv(\"/kaggle/input/nlp-getting-started/sample_submission.csv\")\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "205340a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T05:49:02.374225Z",
     "iopub.status.busy": "2023-09-01T05:49:02.373592Z",
     "iopub.status.idle": "2023-09-01T05:49:45.164061Z",
     "shell.execute_reply": "2023-09-01T05:49:45.162882Z"
    },
    "papermill": {
     "duration": 42.845034,
     "end_time": "2023-09-01T05:49:45.166709",
     "exception": false,
     "start_time": "2023-09-01T05:49:02.321675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 181ms/step\n"
     ]
    }
   ],
   "source": [
    "sample_submission[\"target\"] = np.argmax(classifier.predict(X_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49c02bfb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T05:49:45.292104Z",
     "iopub.status.busy": "2023-09-01T05:49:45.291720Z",
     "iopub.status.idle": "2023-09-01T05:49:45.313081Z",
     "shell.execute_reply": "2023-09-01T05:49:45.312126Z"
    },
    "papermill": {
     "duration": 0.083513,
     "end_time": "2023-09-01T05:49:45.315281",
     "exception": false,
     "start_time": "2023-09-01T05:49:45.231768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758f92db",
   "metadata": {
    "papermill": {
     "duration": 0.059722,
     "end_time": "2023-09-01T05:49:45.433961",
     "exception": false,
     "start_time": "2023-09-01T05:49:45.374239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "kernelspec": {
  "display_name": "Python 3",
  "language": "python",
  "name": "python3"
 },
 "language_info": {
  "codemirror_mode": {
   "name": "ipython",
   "version": 3
  },
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "nbconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": "3.6.4"
 },
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 424.813995,
   "end_time": "2023-09-01T05:49:48.887705",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-09-01T05:42:44.073710",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
